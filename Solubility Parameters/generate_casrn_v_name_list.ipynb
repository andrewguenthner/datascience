{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a list of chemical names and CAS Registry Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function:  This notebook generates a database table of Chemical Abstract Service Registry Numbers from substance names. \n",
    "Rationale:  The database table allows the CAS Registry Number to be used as an index for subsequent manipulations with \n",
    "solubility parameter data, enabling rapid and unambiguous operations on solvent sets.  Using a large data set now will make the system extensible for widespread use later. Having a custom notebook do this job ensures compatibility and\n",
    "isolates the solubility parameter code from dependency on external sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies / Requirements\n",
    "The standard sqlite3 library is used. The XML library also needs to be installed.  The notebook expects a source file named\n",
    "'chemid_latest.xml' to be located in a folder called 'chemidplus' within a folder named 'Data_Sources' co-located with this notebook.  Special note:  due to the large size of the unzipped .xml file, it is not provided in the GitHub source.  Instead,\n",
    "a zipped version is provided on GitHub.  When downloading source code from GitHub, unzip the file and place it in a folder\n",
    "named chemidplus in Data_Sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note:  **Input file size is very large -- ~ 1 GB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import sqlite3 \n",
    "# Input file\n",
    "infile = 'Data_Sources/chemidplus/chemid_latest.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the input file and convert it to an XML tree -- root.tag should return\n",
    "# 'file' if this executes correctly -- this step takes some time to execute\n",
    "with open(infile,'r') as f:\n",
    "    tree = ET.parse(infile)\n",
    "root = tree.getroot()\n",
    "root.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420658"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FYI, print the number of chemicals in the root -- this should be several hundred k\n",
    "len(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read in the data, we will first make lists\n",
    "# Later, we'll put these in DataFrames to process quickly\n",
    "# For now, just make lists of name, CASRN and CASRN, synonym\n",
    "prim_name = []\n",
    "casrn = []\n",
    "casrn_syn = []\n",
    "syn = []\n",
    "\n",
    "for substance in range(len(root)):\n",
    "    subst_name = root[substance][0].find('NameOfSubstance')\n",
    "    subst_cas = root[substance][1].find('CASRegistryNumber')\n",
    "    \n",
    "    # Skip all list additions if there is not both a main name and CASRN\n",
    "    if subst_name is not None and subst_cas is not None:\n",
    "        prim_name.append(subst_name.text)\n",
    "        casrn.append(subst_cas.text)\n",
    "        \n",
    "        # Check if there is a systematic name\n",
    "        subst_syst = root[substance][0].find('SystematicName')\n",
    "        \n",
    "        # Add it to synonym list if there is\n",
    "        if subst_syst is not None:\n",
    "            casrn_syn.append(subst_cas.text)\n",
    "            syn.append(subst_syst.text)\n",
    "            \n",
    "        # Check if there are synonyms\n",
    "        subst_syn = root[substance][0].findall('Synonyms')\n",
    "        \n",
    "        # Add if there are any ...\n",
    "        if len(subst_syn) != 0:\n",
    "            for synonym in subst_syn:\n",
    "                casrn_syn.append(subst_cas.text)\n",
    "                syn.append(synonym.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, convert lists to DataFrames for further processing\n",
    "name_CAS_df = pd.DataFrame({'Subst_Name':prim_name,'CASRN':casrn})\n",
    "synonyms_df = pd.DataFrame({'CASRN':casrn_syn,'Synonym':syn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_CAS has 120692 rows with 119838 unique names.\n",
      "name_CAS has 120692 unique CAS Registry Numbers.\n",
      "Synonyms table has 706245 rows with 690191 synonyms.\n"
     ]
    }
   ],
   "source": [
    "# Get some DataFrame info on length and unique values\n",
    "print (f'name_CAS has {len(name_CAS_df)} rows with {name_CAS_df.Subst_Name.nunique()} unique names.')\n",
    "print (f'name_CAS has {name_CAS_df.CASRN.nunique()} unique CAS Registry Numbers.')\n",
    "print (f'Synonyms table has {len(synonyms_df)} rows with {synonyms_df.Synonym.nunique()} synonyms.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "What you should see is no duplicate CAS Registry Numbers, some duplicated names, and quite a few duplicated synonyms...\n",
    "The following cells take care of the easy stuff ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop cases where name, CAS pairs are duplicates -- there should not be any to start with\n",
    "# but just in case there are, ths is a quick way that would fix it\n",
    "name_CAS_df.drop_duplicates(inplace = True)\n",
    "# For the synonyms column, drop duplicated CASRN, synonym pairs -- this usually represents a majority of cases\n",
    "synonyms_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows of the Synonyms where the Synonym, CASRN pair is the same as a name, CASRN pair\n",
    "synonyms_df = synonyms_df.merge(name_CAS_df, left_on = ['Synonym','CASRN'], right_on = ['Subst_Name','CASRN'], \n",
    "                                how='left', indicator=True).query('_merge == \"left_only\"').drop('_merge', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_CAS has 120692 rows with 119838 unique names.\n",
      "name_CAS has 120692 unique CAS Registry Numbers.\n",
      "Synonyms table has 643629 rows with 638199 synonyms.\n"
     ]
    }
   ],
   "source": [
    "# Now check the results ...\n",
    "print (f'name_CAS has {len(name_CAS_df)} rows with {name_CAS_df.Subst_Name.nunique()} unique names.')\n",
    "print (f'name_CAS has {name_CAS_df.CASRN.nunique()} unique CAS Registry Numbers.')\n",
    "print (f'Synonyms table has {len(synonyms_df)} rows with {synonyms_df.Synonym.nunique()} synonyms.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tackle ambiguous entries, we will make use of the fact that CAS Registry Numbers reflect the order of entry,\n",
    "thus the more \"common\" compound is entered first.  We will assign a CAS priority number, sort on this, and \n",
    "only keep the duplicate with the lower number in the primary name table.  We will take the alternates to a separate\n",
    "table for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the CAS Registry Number -- the last digit is a checksum and can be dropped\n",
    "name_CAS_df['CASRank'] = name_CAS_df.CASRN.str.split('-',3).apply(lambda x : x[0]).astype('int') * 100 \\\n",
    "                      + name_CAS_df.CASRN.str.split('-',3).apply(lambda x : x[1]).astype('int')\n",
    "# Sort by this rank -- the source data is typically sorted already\n",
    "name_CAS_df = name_CAS_df.sort_values(by='CASRank')\n",
    "# Now create duplicate flags\n",
    "name_CAS_df['Dup_Name_Flag'] = name_CAS_df.duplicated('Subst_Name',keep = False)\n",
    "# Drop the rank columns as is it no longer needed\n",
    "name_CAS_df = name_CAS_df.drop(columns='CASRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First grab the duplicates \n",
    "alt_primary_name_df = name_CAS_df[name_CAS_df.duplicated('Subst_Name')]\n",
    "# Now they can be safely dropped from the main table\n",
    "name_CAS_df = name_CAS_df.drop_duplicates('Subst_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_CAS has 119838 rows with 119838 unique names.\n",
      "name_CAS has 119838 unique CAS Registry Numbers.\n",
      "Synonyms table has 643629 rows with 638199 synonyms.\n"
     ]
    }
   ],
   "source": [
    "# Now check the results ...\n",
    "print (f'name_CAS has {len(name_CAS_df)} rows with {name_CAS_df.Subst_Name.nunique()} unique names.')\n",
    "print (f'name_CAS has {name_CAS_df.CASRN.nunique()} unique CAS Registry Numbers.')\n",
    "print (f'Synonyms table has {len(synonyms_df)} rows with {synonyms_df.Synonym.nunique()} synonyms.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_CAS has 119838 rows with 119838 unique names.\n",
      "name_CAS has 119838 unique CAS Registry Numbers.\n",
      "Synonyms table has 638199 rows with 638199 synonyms.\n"
     ]
    }
   ],
   "source": [
    "# Do for the synonyms table what was done for the name_CASRN table\n",
    "# Parse the CAS Registry Number \n",
    "synonyms_df['CASRank'] = synonyms_df.CASRN.str.split('-',3).apply(lambda x : x[0]).astype('int') * 100 \\\n",
    "                      + synonyms_df.CASRN.str.split('-',3).apply(lambda x : x[1]).astype('int')\n",
    "# Sort by this rank -- the source data is typically sorted already\n",
    "synonyms_df = synonyms_df.sort_values(by='CASRank')\n",
    "# Now create duplicate flags\n",
    "synonyms_df['Dup_Name_Flag'] = synonyms_df.duplicated('Synonym',keep = False)\n",
    "# Drop the rank columns as is it no longer needed\n",
    "synonyms_df = synonyms_df.drop(columns='CASRank')\n",
    "\n",
    "# First grab the duplicates \n",
    "alt_synonyms_df = synonyms_df[synonyms_df.duplicated('Synonym')]\n",
    "# Now they can be safely dropped from the main table\n",
    "synonyms_df = synonyms_df.drop_duplicates('Synonym')\n",
    "\n",
    "# Now check the results ...\n",
    "print (f'name_CAS has {len(name_CAS_df)} rows with {name_CAS_df.Subst_Name.nunique()} unique names.')\n",
    "print (f'name_CAS has {name_CAS_df.CASRN.nunique()} unique CAS Registry Numbers.')\n",
    "print (f'Synonyms table has {len(synonyms_df)} rows with {synonyms_df.Synonym.nunique()} synonyms.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "For validation, the CAS Registry Numbers are checked against names and synonyms from a known solvent set.  The default set\n",
    "is a list of 100 of the most commonly used solvents  for Hansen Solubility Parameter determination, based on Hansen's key experimental work.  Custom validations can be added by placing the name and CAS Registry Number into the 'validation.csv' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2501    Anisole\n",
       "Name: Subst_Name, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_CAS_df.loc[name_CAS_df.CASRN == '100-66-3'].Subst_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58490            EC 202-876-1\n",
       "58488     Phenyl methyl ether\n",
       "58487          Phenoxymethane\n",
       "58486                NSC 7920\n",
       "58485     Methyl phenyl ether\n",
       "58484          Methoxybenzene\n",
       "58483                 HSDB 44\n",
       "58489         UNII-B3W693GAZH\n",
       "58481           FEMA No. 2097\n",
       "58480    Ether, methyl phenyl\n",
       "58479        EINECS 202-876-1\n",
       "58478        Benzene, methoxy\n",
       "58477                  Anizol\n",
       "58476               AI3-00042\n",
       "58482        FEMA Number 2097\n",
       "Name: Synonym, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms_df.loc[synonyms_df.CASRN == '100-66-3'].Synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:  The National Library of Medicine provides the data source ChemIDPlus.  This source provides a monthly update\n",
    "of basic chemical ID information.  It currently lists over 400,000 compounds, and is updated monthly.  Although the main use \n",
    "is for regulatory purposes, it is likely to provide an exhaustive list of solvents.  If making use of this data set, please\n",
    "acknowledge the source and provide the link below to facilitate using the latest version of the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current version of the data is from 03-28-2019.  This script was last executed on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The URL for the latest ChemIDPlus download is:  ftp://ftp.nlm.nih.gov/nlmdata/.chemidlease/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASRN or CAS Registry Number are registered trademarks of the chemical abstracts service.  Organizations that use this data\n",
    "will need a license from the Chemical Abstracts Service.  The current notebook is for educational purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
